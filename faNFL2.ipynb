{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# faNFL - Exploring the possibilities of predicting NFL player performance for Fantasy NFL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Greg Sieranski](http://wonbyte.com) (1) and [Samuel John](http://samueljohn.de) (2)\n",
    "\n",
    "\n",
    "1.  Walmart, USA\n",
    "2.  HÃ¶rSys GmbH, Hannover, Germany\n",
    "\n",
    "An [IPython](http://ipython.org/ipython-doc/dev/interactive/htmlnotebook.html) notebook can be downloaded from **todo: insert URL here after open sourcing**.\n",
    "\n",
    "#### How to cite\n",
    "*todo* after publication (PyCon 2015 poster)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd  # tabular data thingy\n",
    "import seaborn as sns  # nicer statistical plots\n",
    "import matplotlib.pyplot as plt  # the plots work-horse\n",
    "import sklearn  # machine learning\n",
    "import itertools\n",
    "from collections import defaultdict\n",
    "import pyprind\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import our local version of nflgame (ported to Python3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data.groupby(level='player_id').mean()[:14].plot()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys; sys.path.insert(0, \"./nflgame\")\n",
    "import nflgame  # load NFL statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import qgrid  # seems to throw an err on pip install lately\n",
    "#qgrid.nbinstall()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tune IPython notebook towards inline retina graphics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format='svg'\n",
    "%config InlineBackend.figure_format='retina'\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def players_in_game(game, side=None):\n",
    "    \"\"\"Return unique set of `player_id`s for a certain `nflgame.Game` for the given `side`.\"\"\"\n",
    "    cats = ['receiving', 'defense', 'punting', 'kickret', 'kicking', 'rushing', 'puntret', 'passing', 'fumbles']\n",
    "    players_home = (list(game.data['home']['stats'][cat].keys())\n",
    "                    for cat in cats if cat in game.data['home']['stats'])\n",
    "    players_away = (list(game.data['away']['stats'][cat].keys())\n",
    "                    for cat in cats if cat in game.data['away']['stats'])\n",
    "    re = {'home':set(itertools.chain(*players_home)), 'away':set(itertools.chain(*players_away))}\n",
    "    if side is not None:\n",
    "        return re[side]\n",
    "    else:\n",
    "        return re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting the players for a certain year that are in the stats (not all players are)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def active_players_in_year(year):\n",
    "    players = set()\n",
    "    for game in nflgame.games(year):\n",
    "        for side in ['away', 'home']:\n",
    "            players.update(players_in_game(game, side=side))\n",
    "    return players"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def lookup_player_name(player_id):\n",
    "    \"\"\"\n",
    "    Return the name (str) of a player, given his player_id (str).\n",
    "    \"\"\"\n",
    "    return nflgame.players[player_id].full_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def opposite_side(side):\n",
    "    if side == 'home':\n",
    "        return 'away'\n",
    "    elif side == 'away':\n",
    "        return 'home'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def collect_stats_for_keys(keys, games):\n",
    "    cats = {cat for cat, key in keys}\n",
    "    columns = ['site', 'date', 'week', 'team', 'op_team', 'season']\n",
    "    columns += [ cat+\"_\"+key for cat, key in keys]\n",
    "    tmp_list = []\n",
    "    tmp_index = []\n",
    "    for game in games:\n",
    "        playing = {}\n",
    "        for site in ['away', 'home']:\n",
    "            for cat in cats:\n",
    "                if cat not in game.data[site]['stats']:\n",
    "                    continue\n",
    "                stat = game.data[site]['stats'][cat]\n",
    "                for player_id in stat:\n",
    "                    if player_id not in playing:\n",
    "                        playing[player_id] = defaultdict(lambda: None)\n",
    "                    for key in [key for c, key in keys if c == cat]:\n",
    "                        if key in stat[player_id]:\n",
    "                            playing[player_id][cat+\"_\"+key] = stat[player_id][key]\n",
    "                    playing[player_id]['site'] = site\n",
    "                    playing[player_id]['date'] = pd.datetime(game.schedule['year'],\n",
    "                                                             game.schedule['month'],\n",
    "                                                             game.schedule['day'],\n",
    "                                                             int(game.schedule['time'].split(':')[0]))\n",
    "                    playing[player_id]['week'] = game.schedule['week']\n",
    "                    playing[player_id]['team'] = game.data[site]['abbr']\n",
    "                    playing[player_id]['op_team'] = game.data[opposite_side(site)]['abbr']\n",
    "                    playing[player_id]['season'] = game.season()\n",
    "        for player_id in playing:\n",
    "            tmp_index.append([player_id, game.eid])\n",
    "            tmp_list.append([playing[player_id][col] for col in columns])\n",
    "    return pd.DataFrame(tmp_list,\n",
    "                        index=pd.MultiIndex.from_tuples(tmp_index, names=('player_id', 'eid')),\n",
    "                        columns=columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and test data set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are just lists of all nflgame games in `nflgame.Game` objects. We transform them to an useful pandas data frame further below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_set = list(itertools.chain(*(nflgame.games(year) for year in [2009, 2010, 2011, 2012, 2013])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_set = list(itertools.chain(*(nflgame.games(year) for year in [2014])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to define the `nflgame` keys (for the games) that are interesting to us in order to build up a DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "offense_keys= [('receiving', 'tds'),\n",
    "               ('receiving', 'yds'),\n",
    "               ('receiving', 'rec'),\n",
    "               ('receiving', 'lng'),\n",
    "               ('receiving', 'twoptm'),\n",
    "               ('passing', 'yds'),\n",
    "               ('passing', 'tds'),\n",
    "               ('passing', 'att'),\n",
    "               ('passing', 'cmp'),\n",
    "               ('passing', 'ints'),\n",
    "               ('rushing', 'yds'),\n",
    "               ('rushing', 'tds'),\n",
    "               ('rushing', 'att'),\n",
    "               ('rushing', 'lng'),\n",
    "               ('fumbles', 'yds'),\n",
    "               ('fumbles', 'rcv'),\n",
    "               ('fumbles', 'tot'),\n",
    "               ('kickret', 'tds'),\n",
    "               ('kickret', 'avg'),\n",
    "               ('kickret', 'ret'),\n",
    "               ('kicking', 'fga'),\n",
    "               ('kicking', 'fgyds'),\n",
    "               ('kicking', 'xpb'),\n",
    "               ('kicking', 'xpmade'),\n",
    "               ('kicking', 'fgm'),\n",
    "               ('puntret', 'lng'),\n",
    "               ('puntret', 'ret'),\n",
    "               ('puntret', 'tds'),\n",
    "               ('puntret', 'avg')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "defense_keys=[('defense', 'ffum'),\n",
    "              ('defense', 'ast'),\n",
    "              ('defense', 'int'),\n",
    "              ('defense', 'sk'),\n",
    "              ('defense', 'tkl'),\n",
    "              ('punting', 'yds'),\n",
    "              ('punting', 'i20'),\n",
    "              ('punting', 'avg'),\n",
    "              ('punting', 'lng')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# keep_keys = ['site', 'date', 'week', 'team', 'op_team', 'season', 'n_op']\n",
    "# keep_keys += [cat+\"_\"+key for cat, key in offense_keys+defense_keys]\n",
    "# keep_keys += [\"ops_\"+cat+\"_\"+key for cat, key in offense_keys+defense_keys]\n",
    "\n",
    "# d = data_test.copy()\n",
    "# for c in d.columns:\n",
    "#     if c in keep_keys:\n",
    "#         continue\n",
    "#     else:\n",
    "#         del d[c]\n",
    "#         print(c)\n",
    "# data_test = d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Appending columns that sum up the opposing team performance\n",
    "\n",
    "... by summing over the mean performance of the players of the opposing team. Hopefully this is a valuable input to the predictors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def append_ops_columns(data, keys=None):\n",
    "    mean_values = data.groupby(level='player_id').mean()\n",
    "    grouped_by_game = data.groupby(level='eid').groups\n",
    "    game_ids = data.index.levels[1]\n",
    "    \n",
    "    # Creating the new column names by going through the offense_keys\n",
    "    # and prepending \"ops_\".\n",
    "    new_columns = {}\n",
    "    for key in keys:\n",
    "        new_columns[\"ops_{0}_{1}\".format(*key)] = []\n",
    "    new_columns['n_op'] = []\n",
    "    bar = pyprind.ProgBar(len(game_ids))\n",
    "    for game_id in game_ids:\n",
    "        players = players_in_game(nflgame.game.Game(game_id))\n",
    "        for player_id, row in data.loc[grouped_by_game[game_id]].iterrows():\n",
    "            opposing_players = players[opposite_side(row['site'])]\n",
    "            n = len(opposing_players)\n",
    "            for what in keys:\n",
    "                what_key = \"{0}_{1}\".format(*what)\n",
    "                new_columns[\"ops_\"+what_key].append(\n",
    "                    np.nansum([mean_values.loc[op_id, what_key] for op_id in opposing_players])/n)\n",
    "            new_columns['n_op'].append(n)\n",
    "        bar.update()\n",
    "    \n",
    "    # making a new DataFrame for the new columns (ops = opposing player's sum)\n",
    "    for column_name in new_columns:\n",
    "        data[column_name] = new_columns[column_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Filling pandas table\n",
    "\n",
    "Let's have a big DataFrame (that is a table) with all games (we are interested in) and how all players performed in that games. When a player wasn't in a game, we denote that by `NaN` (that is `None`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now these are the DataFrames for training (\"data\") and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hdf_file = Path(\".\")/\"data.h5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if hdf_file.exists():\n",
    "    print(\"Loading HDF5 file {} that was last updated on\".format(hdf_file))\n",
    "    print(str(pd.datetime.fromtimestamp(hdf_file.stat().st_mtime)), flush=True)\n",
    "    store = pd.HDFStore(str(hdf_file))\n",
    "    data = store['data']\n",
    "    data_test = store['data_test']\n",
    "    store.close()\n",
    "else:\n",
    "    print(\"Collecting stats for offense and defense keys\", flush=True)\n",
    "    data = collect_stats_for_keys(keys=offense_keys+defense_keys,\n",
    "                                 games=train_set)\n",
    "    data_test = collect_stats_for_keys(keys=offense_keys+defense_keys,\n",
    "                                 games=test_set)\n",
    "    data.insert(0,'pos', [nflgame.players[v[0]].position for v in data.index.values])\n",
    "    data_test.insert(0,'pos', [nflgame.players[v[0]].position for v in data_test.index.values])\n",
    "    print(\"Computing normalized ops values for data\")\n",
    "    append_ops_columns(data, keys=offense_keys+defense_keys)\n",
    "    print(\"Computing normalized ops values for data_test\")\n",
    "    append_ops_columns(data_test, keys=offense_keys+defense_keys)\n",
    "    store = pd.HDFStore(str(hdf_file))\n",
    "    store['data'] = data\n",
    "    store['data_test'] = data_test\n",
    "    store.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_data_columns = [cat+\"_\"+key for cat, key in offense_keys+defense_keys]\n",
    "all_data_ops_columns = [\"ops_\"+cat+\"_\"+key for cat, key in offense_keys+defense_keys]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "team_home_stats_per_game = data.fillna(0)[data['site']=='home'].sum(level='eid').loc[:,all_data_columns]\n",
    "team_away_stats_per_game = data.fillna(0)[data['site']=='away'].sum(level='eid').loc[:,all_data_columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting a set of player we are interested in"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining active players of 2014\n",
    "\n",
    "...by basically saying that they need to participate in at least `n` games. Participate means that nfl has some stats for them in the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n = 10\n",
    "# Doing a set comprehension here to get unique ids after we grouped and counted the 'site' column.\n",
    "# The 'site' column is probably always there, so it is a safe bet, but we could used other colums \n",
    "# that do not contain nans.\n",
    "active_players_in_data_test = {ind[0]\n",
    "    for ind in data_test.groupby(level='player_id').filter(lambda x: x['site'].count() >= n).index.values}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So lets see how many players we removed by looking at the 0-th element for all the indices in `data_test.index.values`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len({ v[0] for v in data_test.index.values})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... compared to the number of interesting players in 2014:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(active_players_in_data_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining active players of the train `data`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n = 10\n",
    "# Doing a set comprehension here to get unique ids after we grouped and counted the 'site' column.\n",
    "# The 'site' column is probably always there, so it is a safe bet, but we could used other colums \n",
    "# that do not contain nans.\n",
    "active_players_in_data = {ind[0]\n",
    "    for ind in data.groupby(level='player_id').filter(lambda x: x['site'].count() >= n).index.values}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(active_players_in_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many players are in the train data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(data.groupby(level='player_id').groups)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Does the performance (measures) correlate on the performance of the opponent players *in that one game*?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we want to see if our idea about the **opponent player summed up average stats (ops)** has any predictive power on the performance of a player. Therefore we plot a performance measure like `receiving_yds` vs. different ops values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "team_stats_per_game = team_away_stats_per_game.join(team_home_stats_per_game[all_data_columns], lsuffix=\"_h\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#sns.set(context=\"paper\", font=\"monospace\")\n",
    "\n",
    "corrmat = team_stats_per_game.corr().iloc[:len(team_away_stats_per_game.columns),\n",
    "                                           len(team_away_stats_per_game.columns):]\n",
    "f, ax = plt.subplots(figsize=(12, 12))\n",
    "sns.heatmap(corrmat,\n",
    "            vmax=.4, linewidths=0,\n",
    "            ax=ax)\n",
    "\n",
    "f.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sns.set(style=\"darkgrid\")\n",
    "color = sns.color_palette()[1]\n",
    "g = sns.jointplot(team_home_stats_per_game[\"rushing_att\"],\n",
    "                  team_away_stats_per_game[\"rushing_att\"], kind=\"reg\",\n",
    "                  color=color, size=9, joint_kws=dict())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# $f(k,player_{home},game) = \\frac{\\sum_{p=1}^{N(players_{away,game})}\\frac{\\sum_{g=1}^{N(games_p)}C_k(g,p)}{N(games_p)}}{N(players_{away,game})}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sns.jointplot?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sns.set(style=\"darkgrid\")\n",
    "color = sns.color_palette()[1]\n",
    "d = normalized_data\n",
    "d = d[(d['pos']=='QB')]#.loc[nflgame.find(\"Shaun Hill\")[0].player_id]\n",
    "g = sns.jointplot(d[\"passing_yds\"],\n",
    "                  d[\"ops_receiving_yds\"]*20, kind=\"reg\",\n",
    "                  color=color, size=9)\n",
    "d = d[(d['pos']=='QB')]#.loc[nflgame.find(\"Shaun Hill\")[0].player_id]\n",
    "g = sns.jointplot(d[\"passing_yds\"],\n",
    "                  d[\"ops_defense_tkl\"]*20, kind=\"reg\",\n",
    "                  color=color, size=9)\n",
    "d = d[(d['pos']=='QB')]#.loc[nflgame.find(\"Shaun Hill\")[0].player_id]\n",
    "g = sns.jointplot(d[\"passing_yds\"],\n",
    "                  d[\"ops_kicking_fga\"]*20, kind=\"reg\",\n",
    "                  color=color, size=9)\n",
    "d = d[(d['pos']=='QB')]#.loc[nflgame.find(\"Shaun Hill\")[0].player_id]\n",
    "g = sns.jointplot(d[\"passing_yds\"],\n",
    "                  d[\"ops_defense_ffum\"]*20, kind=\"reg\",\n",
    "                  color=color, size=9)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\"ops_receiving_yds\", \"ops_defense_tkl\", \"ops_kicking_fga\", \"ops_defense_ffum\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sns.jointplot?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "color = sns.color_palette()[1]\n",
    "d = normalized_data[normalized_data[\"pos\"] == \"RB\"]#.loc[nflgame.find(\"Peyton Manning\")[0].player_id]\n",
    "g = sns.jointplot(d[\"kickret_ret\"],\n",
    "                  d[\"ops_kicking_xpmade\"]*100, kind=\"reg\",\n",
    "                  color=color, size=9)\n",
    "d = normalized_data_test[normalized_data_test[\"pos\"] == \"RB\"]#.loc[nflgame.find(\"Peyton Manning\")[0].player_id]\n",
    "color = sns.color_palette()[2]\n",
    "g = sns.jointplot(d[\"kickret_ret\"],\n",
    "                  d[\"ops_kicking_xpmade\"]*100, kind=\"reg\",\n",
    "                  color=color, size=9)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "linreg_models = {}\n",
    "linreg_generic_model = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "measures_to_predict = [\"{0}_{1}\".format(cat, key) for cat, key in offense_keys]\n",
    "players_to_predict = active_players_in_data_test & active_players_in_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ops_values_per_team = data.groupby('op_team').mean().loc[:,all_data_ops_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "scale_ops_values = StandardScaler().fit(ops_values_per_team)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def makelike(arr,df):\n",
    "    return pd.DataFrame(arr,index=df.index,columns=df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12, 12))\n",
    "sns.set_palette(\"husl\")\n",
    "sns.heatmap(makelike(scale_ops_values.transform(ops_values_per_team),\n",
    "                     ops_values_per_team),\n",
    "            linewidths=.4)\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.set_palette(\"pastel\")\n",
    "makelike(scale_ops_values.transform(ops_values_per_team),ops_values_per_team)[['ops_passing_yds','ops_passing_tds']].plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cluster the teams based on their ops values \n",
    "to see which teams are similar to each other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA,  KernelPCA\n",
    "from sklearn.manifold import MDS, TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pca =  KernelPCA(n_components=2, kernel=\"linear\", gamma=10, fit_inverse_transform=True)\n",
    "#pca = TSNE(n_components=2)\n",
    "tmp_data = makelike(scale_ops_values.transform(ops_values_per_team),\n",
    "                    ops_values_per_team)\n",
    "teams_in_2d = pca.fit_transform(tmp_data)\n",
    "teams_in_2d = pd.DataFrame(teams_in_2d,index=ops_values_per_team.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12,6))\n",
    "sns.set_palette(\"pastel\")\n",
    "teams_in_2d.plot(0,1,kind='scatter', s=100,ax=ax)\n",
    "for team in teams_in_2d.index.values:\n",
    "    ax.annotate(team, teams_in_2d.loc[team])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training phase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalizing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "player_means = data.groupby(level='player_id').mean()[all_data_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "normalized_data = data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_player_in_data = list(set(v[0] for v in data.index.values))\n",
    "for pid in pyprind.prog_bar(all_player_in_data):\n",
    "    normalized_data.loc[[pid],all_data_columns] -= player_means.loc[[pid],all_data_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "normalized_data_test = data_test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "player_means_test = data_test.groupby(level='player_id').mean()[all_data_columns]\n",
    "all_player_in_data_test = list(set(v[0] for v in data_test.index.values))\n",
    "for pid in pyprind.prog_bar(all_player_in_data_test):\n",
    "    normalized_data_test.loc[[pid],all_data_columns] -= player_means_test.loc[[pid],all_data_columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Computing coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ops_corrmat = normalized_data.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ops_corrmat = data.loc[data['pos']=='QB'].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(9, 9))\n",
    "sns.set_palette(\"husl\")\n",
    "sns.heatmap(ops_corrmat.loc[all_data_columns,\n",
    "                            all_data_ops_columns],\n",
    "            linewidths=.4, vmin=-.2, vmax=0.2)\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ops_test_corrmat = data_test.loc[data_test['pos']=='QB'].corr()\n",
    "fig, ax = plt.subplots(figsize=(9, 9))\n",
    "sns.set_palette(\"husl\")\n",
    "sns.heatmap(ops_test_corrmat.loc[all_data_columns,\n",
    "                                 all_data_ops_columns],\n",
    "            linewidths=.4, vmin=-.3, vmax=0.3)\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(9, 9))\n",
    "corr_agreement = (ops_test_corrmat*ops_corrmat)#.mul(data[all_data_columns].count()/len(data), axis=0)\n",
    "corr_agreement = corr_agreement.loc[all_data_columns,\n",
    "                                    all_data_ops_columns]\n",
    "sns.set_palette(\"husl\")\n",
    "sns.heatmap(corr_agreement,\n",
    "            linewidths=.4, vmin=-0.1, vmax=.1)\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(9, 9))\n",
    "corr_agreement = ops_test_corrmat*ops_corrmat\n",
    "corr_agreement = corr_agreement.loc[all_data_columns,\n",
    "                                    all_data_ops_columns]\n",
    "sns.set_palette(\"husl\")\n",
    "sns.heatmap(corr_agreement,\n",
    "            linewidths=.4, vmax=0.01)\n",
    "fig.tight_layout()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using PCA projections as summary for the opposing team for training a LinearRegression on each player indivudually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "bar = pyprind.ProgBar(len(players_to_predict)*len(measures_to_predict))\n",
    "player_models = {}\n",
    "for player in players_to_predict:\n",
    "    player_models[player] = {}\n",
    "    for measure in measures_to_predict:\n",
    "        bar.update()\n",
    "        player_models[player][measure] = LinearRegression()\n",
    "        colums_that_matter = [col for col in corr_agreement.loc[measure].sort(inplace=False, ascending=False)[:top_n].index.values]\n",
    "        if data.loc[player][measure].count() < 40:\n",
    "            #print(\"skipping {0} for {1}\".format(measure,lookup_player_name(player)))\n",
    "            continue\n",
    "        try:\n",
    "            player_models[player][measure].fit(teams_in_2d.loc[data.loc[player]['op_team']],\n",
    "                                               data.loc[player][measure].fillna(data.loc[player][measure].mean()).fillna(0))\n",
    "#             linreg_models[player][measure].fit(data.loc[player,colums_that_matter].dropna(axis=1),\n",
    "#                                                data.loc[player][measure].fillna(data.loc[player][measure].mean()).fillna(0))\n",
    "        except ValueError:\n",
    "            print(data.loc[player,colums_that_matter].dropna())\n",
    "            print(measure)\n",
    "            raise\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using plain top_n columns_that_matter of the oponent teams summed up stats (OPS) to predict each players performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "top_n = 6\n",
    "bar = pyprind.ProgBar(len(players_to_predict)*len(measures_to_predict))\n",
    "player_models = {}\n",
    "for player in players_to_predict:\n",
    "    player_models[player] = {}\n",
    "    for measure in measures_to_predict:\n",
    "        bar.update()\n",
    "        player_models[player][measure] = LinearRegression()\n",
    "        colums_that_matter = [col for col in corr_agreement.loc[measure].sort(inplace=False, ascending=False)[:top_n].index.values]\n",
    "        if data.loc[player][measure].count() < 40:\n",
    "            #print(\"skipping {0} for {1}\".format(measure,lookup_player_name(player)))\n",
    "            continue\n",
    "        try:\n",
    "#             player_models[player][measure].fit(teams_in_2d.loc[data.loc[player]['op_team']],\n",
    "#                                                data.loc[player][measure].fillna(data.loc[player][measure].mean()).fillna(0))\n",
    "            player_models[player][measure].fit(data.loc[player,colums_that_matter].dropna(axis=1),\n",
    "                                               data.loc[player][measure].fillna(data.loc[player][measure].mean()).fillna(0))\n",
    "        except ValueError:\n",
    "            print(data.loc[player,colums_that_matter].dropna())\n",
    "            print(measure)\n",
    "            raise\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A bag for each player type (position)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "top_n = 5\n",
    "linreg_models = {}\n",
    "bags = [\"QB\", \"WR\"]\n",
    "bar = pyprind.ProgBar(len(measures_to_predict)*len(bags))\n",
    "for bag in bags:\n",
    "    all_in_bag = [ pid for pid in players_to_predict if nflgame.players[pid].position == bag] \n",
    "    linreg_models[bag] = {}\n",
    "    for measure in measures_to_predict:\n",
    "        bar.update()\n",
    "        linreg_models[bag][measure] = LinearRegression()\n",
    "        colums_that_matter = [col for col in corr_agreement.loc[measure].sort(inplace=False, ascending=False)[:top_n].index.values]\n",
    "        bag_data = data.loc[data.index.isin([ pid for pid in players_to_predict\n",
    "                                              if nflgame.players[pid].position == bag],\n",
    "                                            level='player_id')]\n",
    "#             linreg_models[bag][measure].fit(teams_in_2d.loc[data.loc[player]['op_team']],\n",
    "#                                                data.loc[player][measure].fillna(data.loc[player][measure].mean()).fillna(0))\n",
    "        linreg_models[bag][measure].fit(bag_data[colums_that_matter].dropna(axis=1),\n",
    "                                        bag_data[measure].fillna(0))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try to cluster players of a certain type (position) into subgroups in each bag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start with one of the most interesting type, the QB:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "QB_data = data[data['pos'] == 'QB'][all_data_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "QB_data.dropna(thresh=len(QB_data)/2, axis=1, how='all', inplace=True)\n",
    "QB_data.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.atleast_2d(QB_data[\"passing_yds\"].groupby(level='player_id').mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import MeanShift\n",
    "from sklearn.mixture import GMM\n",
    "cluster = MeanShift(bandwidth=6)\n",
    "cluster.fit(QB_data[[\"passing_yds\"]].groupby(level='player_id').mean())\n",
    "clusters = cluster.predict(QB_data[[\"passing_yds\"]].groupby(level='player_id').mean())\n",
    "fig, ax = plt.subplots(figsize=(16,8))\n",
    "QB_data[[\"passing_yds\",\"passing_att\"]].groupby(level='player_id').mean().plot(0,1,ax=ax, kind='scatter', s=100,c=clusters, cmap='Set2')\n",
    "tmp = QB_data.iloc[:50]\n",
    "tmp[[\"passing_yds\",\"passing_att\"]].plot(0,1,kind='scatter', ax=ax,\n",
    "                                            s=10,\n",
    "                                            c=pd.Categorical(\n",
    "                                                [v[0] for v in tmp.index.values],\n",
    "                                                categories=set([v[0] for v in tmp.index.values])).codes,\n",
    "                                            cmap='Set2')\n",
    "for v in tmp.index.values:\n",
    "    ax.text(v[0], tmp.loc[v[0]][['passing_yds', 'passing_att']] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.Categorical([v[0] for v in df.index.values],\n",
    "               categories=set([v[0] for v in tmp.index.values]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "#kpca = KernelPCA(n_components=2, kernel=\"rbf\", gamma=1/20, fit_inverse_transform=True)\n",
    "kpca = TSNE(n_components=2)\n",
    "clean_up_normalized_data = normalized_data[[\"pos\"]+all_data_columns]\n",
    "clean_up_normalized_data = clean_up_normalized_data[clean_up_normalized_data['pos'] == 'QB']\n",
    "clean_up_normalized_data.dropna(thresh=len(clean_up_normalized_data)/2, axis=1, how='all', inplace=True)\n",
    "clean_up_normalized_data.fillna(0, inplace=True)\n",
    "norm_data_2d = kpca.fit_transform(clean_up_normalized_data.drop([\"pos\"], axis=1))\n",
    "fig, ax = plt.subplots(figsize=(16,8))\n",
    "df = pd.DataFrame(norm_data_2d, index=clean_up_normalized_data.index)\n",
    "df.plot(0,1,\n",
    "        kind='scatter',\n",
    "        s=100,ax=ax,\n",
    "        c=pd.Categorical([v[0] for v in df.index.values],\n",
    "               categories=set([v[0] for v in df.index.values])).codes, cmap=\"Set2\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d.axes3d import Axes3D\n",
    "fig, ax = plt.subplots(subplot_kw=dict(projection='3d'), figsize=(12,12))\n",
    "tmp = []\n",
    "colors = sns.color_palette(\"Set2\",24)\n",
    "groupmean = data[\"receiving_yds\"].mean()\n",
    "for i, pid in enumerate(p for p in players_to_predict if nflgame.players[p].position == 'QB'):\n",
    "    xs = normalized_data.loc[[pid],'receiving_yds']\n",
    "    ax.scatter(xs,\n",
    "               data.loc[[pid],\"ops_defense_ffum\"],\n",
    "               data.loc[[pid],\"ops_defense_tkl\"],\n",
    "#                teams_in_2d.loc[data.loc[[pid],'op_team']][0],\n",
    "#                teams_in_2d.loc[data.loc[[pid],'op_team']][1],\n",
    "               c=\"black\", cmap=\"Set2\", marker=\".\",\n",
    "               label=lookup_player_name(pid))\n",
    "    xs = data.loc[[pid],'receiving_yds']\n",
    "    ax.scatter(xs-groupmean,\n",
    "               data.loc[[pid],\"ops_defense_ffum\"],\n",
    "               data.loc[[pid],\"ops_defense_tkl\"],\n",
    "#                teams_in_2d.loc[data.loc[[pid],'op_team']][0],\n",
    "#                teams_in_2d.loc[data.loc[[pid],'op_team']][1],\n",
    "                marker=\"x\", cmap=\"Set2\",\n",
    "               label=lookup_player_name(pid))\n",
    "\n",
    "\n",
    "    \n",
    "ax.set_xlabel(\"receiving_yds\")\n",
    "ax.set_ylabel(\"ops_defense_ffum\")\n",
    "ax.set_zlabel(\"ops_defense_tkl\")\n",
    "ax.legend()\n",
    "ax.view_init(90,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import MeanShift, KMeans\n",
    "from sklearn.mixture import GMM\n",
    "from sklearn.linear_model import Ridge\n",
    "from copy import deepcopy\n",
    "top_n = 2\n",
    "n_cluster = 1\n",
    "linreg_models = {}\n",
    "player_models = {}\n",
    "columns_for_bag = {}\n",
    "ops_columns_that_matter ={}\n",
    "bags = [\"QB\"]\n",
    "kmeans = {}\n",
    "columns_that_matter = None\n",
    "bar = pyprind.ProgBar(len(measures_to_predict)*len(bags)*n_cluster)\n",
    "for bag in bags:\n",
    "    linreg_models[bag] = {} \n",
    "    # get all the data for the players of the type (position) as in `bag`:\n",
    "    bag_data_ops = normalized_data[normalized_data['pos'] == bag][all_data_ops_columns]\n",
    "    bag_data = normalized_data[normalized_data['pos'] == bag][['op_team']+all_data_columns]\n",
    "    bag_data.dropna(thresh=len(bag_data)/40, axis=1, how='all', inplace=True)\n",
    "    bag_data.fillna(0, inplace=True)\n",
    "    \n",
    "    # Split into clusters\n",
    "    kmeans[bag] = KMeans(n_clusters=n_cluster)\n",
    "    if bag == \"QB\":\n",
    "        cluster_based_on = bag_data.drop(\"op_team\",axis=1)[['passing_yds']]\n",
    "        columns_that_matter = [\"ops_receiving_yds\", \"ops_defense_tkl\"]\n",
    "    elif bag == \"RB\":\n",
    "        cluster_based_on = bag_data.drop(\"op_team\",axis=1)[['kickret_ret']]\n",
    "        columns_that_matter = [\"ops_kicking_fgm\", \"ops_kicking_xpmade\"]\n",
    "    else:\n",
    "        raise Exception(\"palyer type not yet supported\")\n",
    "    ops_columns_that_matter[bag] = columns_that_matter\n",
    "    columns_for_bag[bag] = cluster_based_on.columns\n",
    "    kmeans[bag].fit(cluster_based_on)\n",
    "    clusters = kmeans[bag].predict(cluster_based_on)\n",
    "    for cluster_nr in set(clusters):\n",
    "        linreg_models[bag][cluster_nr] = {}\n",
    "        cluster_bag_data = bag_data_ops.loc[clusters == cluster_nr]\n",
    "        for measure in measures_to_predict:\n",
    "            try:\n",
    "                bar.update()\n",
    "                linreg_models[bag][cluster_nr][measure] = linear_model.Ridge(fit_intercept=True, alpha=.1)\n",
    "#                columns_that_matter = [col for col in corr_agreement.loc[measure].sort(inplace=False, ascending=False)[:top_n].index.values]\n",
    "                \n",
    "                linreg_models[bag][cluster_nr][measure].fit(cluster_bag_data[columns_that_matter],\n",
    "                                                            bag_data.loc[clusters==cluster_nr][measure])\n",
    "\n",
    "#.fit(teams_in_2d.loc[data.loc[player]['op_team']],\n",
    "#                                                data.loc[player][measure].fillna(data.loc[player][measure].mean()).fillna(0))\n",
    " \n",
    "# code for fitting based on 2d reduced ops team representation\n",
    "#                linreg_models[bag][cluster_nr][measure].fit(teams_in_2d.loc[bag_data.loc[clusters==cluster_nr]['op_team']],\n",
    "#                                                            bag_data.loc[clusters==cluster_nr][measure])\n",
    "\n",
    "                # Get all players in this cluster and assign the model to them:\n",
    "                for pid in [ v[0] for v in bag_data.loc[clusters==cluster_nr].index.values]:\n",
    "                    if not pid in player_models:\n",
    "                        player_models[pid] = {}\n",
    "                    player_models[pid][measure] = linreg_models[bag][cluster_nr][measure]\n",
    "                    #player_models[pid][measure].intercept_ = (player_models[pid][measure].coef_ * -player_means.loc[pid][columns_that_matter])+player_means.loc[pid,measure]\n",
    "\n",
    "            except KeyError as e:\n",
    "                ...\n",
    "                #del linreg_models[bag][cluster_nr][measure]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying the prediction on test data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Exclude outlier \n",
    "pid = nflgame.find(\"Brian Hoyer\")[0].player_id\n",
    "players_to_predict = {p for p in players_to_predict if p != pid}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predicted = {}\n",
    "true = {}\n",
    "d = normalized_data \n",
    "weighting_of_bag_model = .4\n",
    "measure = \"passing_yds\"\n",
    "#measure = \"kickret_ret\"\n",
    "\n",
    "for pid in pyprind.prog_bar([ pid for pid in players_to_predict if nflgame.players[pid].position == 'QB']):\n",
    "    _predicted = []\n",
    "    _true = []\n",
    "    bag = nflgame.players[pid].position\n",
    "    try:\n",
    "        for game in d.loc[pid].index.values:\n",
    "            # next line for prediction based on 2d\n",
    "#            _predicted.append(player_models[pid][measure].predict(\n",
    "#                  teams_in_2d.loc[d.loc[(pid,game)]['op_team']]))\n",
    "            # next line for based on columns that matter\n",
    "            _predicted.append(\n",
    "                player_models[pid][measure].predict(\n",
    "                    d.loc[(pid,game)][ops_columns_that_matter[bag]])*weighting_of_bag_model\n",
    "                          + player_means.loc[pid][measure] )\n",
    "            _true.append(data.loc[(pid,game)][measure])\n",
    "            if np.isnan(_true[-1]):\n",
    "                print(\"Warning: NAN for \"+lookup_player_name(pid)+\" in game \"+game+ \" for measure \"+ measure)\n",
    "\n",
    "        true[pid] = np.array(_true)\n",
    "        predicted[pid] = np.array(_predicted).reshape(-1)\n",
    "    except sklearn.utils.validation.NotFittedError:\n",
    "        continue    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictor_off = []\n",
    "mean_off = []\n",
    "#predictions = []\n",
    "for pid in predicted.keys():\n",
    "    df = pd.DataFrame(index=d.loc[pid].index.values) \n",
    "    df['true'] = true[pid]\n",
    "    df['lin_predictor'] = predicted[pid]\n",
    "    df['mean_predictor'] = data.loc[pid][measure].mean()\n",
    "    df['lin_predictor'] -= true[pid]\n",
    "    df['mean_predictor'] -= true[pid]\n",
    "    df['true'] -= true[pid]\n",
    "    mean_off.append(df['mean_predictor'].abs().sum())\n",
    "    predictor_off.append(df['lin_predictor'].abs().sum())\n",
    "result = pd.DataFrame({'lin_pred':predictor_off,'mean':mean_off},\n",
    "                      index=[lookup_player_name(pid) for pid in predicted.keys()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sns.set_palette('pastel')\n",
    "print(result.sum())\n",
    "result.plot(kind='bar', figsize=(13,6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "measure=\"passing_yds\"\n",
    "pid = nflgame.find(\"Aaron Rodgers\")[0].player_id\n",
    "p = []\n",
    "m = []\n",
    "t = []\n",
    "d = normalized_data_test ## XXXXXX FIX ME\n",
    "d2 = data_test\n",
    "for game in d.loc[pid].index.values:\n",
    "#     print(\"predicted based on bag model:\")\n",
    "#     print(p[-1])\n",
    "#     print(\"predicted based on individual player mean:\")\n",
    "    m.append(player_means.loc[pid][measure])\n",
    "    p.append(m[-1]+10*weighting_of_bag_model*player_models[pid][measure].predict(d.loc[(pid,game)][ops_columns_that_matter['QB']])[0])\n",
    "\n",
    "\n",
    "    #     print(m[-1])\n",
    "#     print(\"True:\")\n",
    "    t.append(d2.loc[(pid,game)][measure])\n",
    "#     print(t[-1])\n",
    "#     print(\"-----\")\n",
    "pd.DataFrame(dict(lin_pred=p, mean=m, true=t)).plot(marker=\"o\", lw=.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### version info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%install_ext https://raw.githubusercontent.com/rasbt/watermark/master/watermark.py\n",
    "%load_ext watermark\n",
    "%watermark --updated -c %Y-%m-%d -v -m -p numpy,scipy,matplotlib,seaborn,pandas -g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}